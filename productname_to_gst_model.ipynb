{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqBNHQtMafHrayYBT2MEul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wardayX/cyhack/blob/main/productname_to_gst_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Imports  \n",
        "Install and import all required libraries.\n"
      ],
      "metadata": {
        "id": "neL9KG6bcjUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xavitI9Nb0w-"
      },
      "outputs": [],
      "source": [
        "!pip install pandas pdfplumber fuzzywuzzy python-Levenshtein sentence-transformers\n",
        "\n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "from fuzzywuzzy import process as fuzzy_process\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import re\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"Libraries installed and imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Upload Functions  \n",
        "Define helper functions to upload the HSN PDF and GST CSV."
      ],
      "metadata": {
        "id": "ODQTkqAQcrkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_hsn_pdf():\n",
        "    print(\"Please upload your HSN Code PDF (SL NO, HS CODE, DESCRIPTION columns).\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded.\")\n",
        "        return None, None\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    print(f\"Uploaded '{file_name}'\")\n",
        "    return file_name, uploaded[file_name]\n",
        "\n",
        "def upload_gst_csv():\n",
        "    print(\"\\nPlease upload your GST Rates CSV.\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded.\")\n",
        "        return None, None\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    print(f\"Uploaded '{file_name}'\")\n",
        "    return file_name, uploaded[file_name]\n",
        "\n",
        "print(\"File upload functions defined.\")"
      ],
      "metadata": {
        "id": "itfhvLvwdVIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse HSN PDF with Aggregate Hierarchical Descriptions\n",
        "Extract HS codes and descriptions from the uploaded PDF with enriching parent HSN codes by concatenating child descriptions.\n"
      ],
      "metadata": {
        "id": "IGlTIflVdWTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_hsn_pdf(pdf_content):\n",
        "    \"\"\"\n",
        "    Parses the HSN PDF to extract HS Codes and Descriptions.\n",
        "    This is a generic attempt and might need fine-tuning based on your PDF's structure.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    try:\n",
        "        with pdfplumber.open(io.BytesIO(pdf_content)) as pdf:\n",
        "            for i, page in enumerate(pdf.pages):\n",
        "                print(f\"Processing PDF page {i+1}/{len(pdf.pages)}...\")\n",
        "                tables = page.extract_tables()\n",
        "                if tables:\n",
        "                    for table in tables:\n",
        "                        header = table[0]\n",
        "                        if header and 'HS CODE' in str(header).upper() and 'DESCRIPTION' in str(header).upper():\n",
        "                            data_rows = table[1:]\n",
        "                        else:\n",
        "                            data_rows = table\n",
        "\n",
        "                        for row in data_rows:\n",
        "                            if len(row) >= 3:\n",
        "                                sl_no, hs_code, description = row[0], row[1], row[2]\n",
        "                                hs_code = str(hs_code).replace('\\n', ' ').strip() if hs_code else None\n",
        "                                description = str(description).replace('\\n', ' ').strip() if description else None\n",
        "                                if hs_code and description:\n",
        "                                    data.append({'HS_Code_PDF': hs_code, 'Description_PDF': description})\n",
        "                    continue\n",
        "\n",
        "                text = page.extract_text()\n",
        "                if text:\n",
        "                    lines = text.split('\\n')\n",
        "                    for line in lines:\n",
        "                        match_hs = re.search(r'^\\s*(\\d{4,8})\\s+(.+)', line)\n",
        "                        if match_hs:\n",
        "                            hs_code = match_hs.group(1).strip()\n",
        "                            description = match_hs.group(2).strip()\n",
        "                            description = re.sub(r'\\s{2,}', ' ', description)\n",
        "                            if hs_code and description:\n",
        "                                data.append({'HS_Code_PDF': hs_code, 'Description_PDF': description})\n",
        "                        else:\n",
        "                            print(f\"Could not parse line: {line}\")\n",
        "\n",
        "\n",
        "        if not data:\n",
        "            print(\"Warning: No data extracted from PDF. PDF parsing might need custom logic for your file format.\")\n",
        "            print(\"Consider using page.extract_text() and custom regex if tables are not well-structured.\")\n",
        "            return pd.DataFrame(columns=['HS_Code_PDF', 'Description_PDF'])\n",
        "\n",
        "        df_hsn = pd.DataFrame(data)\n",
        "        df_hsn['HS_Code_PDF'] = df_hsn['HS_Code_PDF'].astype(str).str.replace(r'\\W+', '', regex=True).str.strip().str.lower()\n",
        "        df_hsn.dropna(subset=['HS_Code_PDF'], inplace=True)\n",
        "        df_hsn.drop_duplicates(subset=['HS_Code_PDF'], keep='first', inplace=True)\n",
        "        print(f\"Extracted {len(df_hsn)} unique HSN entries from PDF.\")\n",
        "        return df_hsn\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing PDF: {e}\")\n",
        "        print(\"Please ensure the PDF is not scanned (image-based) and has extractable text.\")\n",
        "        return pd.DataFrame(columns=['HS_Code_PDF', 'Description_PDF'])\n",
        "\n",
        "print(\"PDF parsing function defined.\")\n",
        "\n",
        "def aggregate_hsn_descriptions(df_hsn_input):\n",
        "    if df_hsn_input.empty:\n",
        "        print(\"HSN PDF data is empty. Skipping aggregation.\")\n",
        "        return df_hsn_input.copy()\n",
        "\n",
        "    print(\"\\nAggregating hierarchical HSN descriptions from PDF data...\")\n",
        "    df_hsn = df_hsn_input.copy()\n",
        "    df_hsn['HS_Code_PDF'] = df_hsn['HS_Code_PDF'].astype(str)\n",
        "    df_hsn.sort_values(by='HS_Code_PDF', inplace=True)\n",
        "    df_hsn.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    aggregated_descriptions = {}\n",
        "    unique_hs_codes = sorted(df_hsn['HS_Code_PDF'].unique())\n",
        "\n",
        "    for parent_hs in unique_hs_codes:\n",
        "        parent_row = df_hsn[df_hsn['HS_Code_PDF'] == parent_hs]\n",
        "        if parent_row.empty or pd.isna(parent_row['Description_PDF'].iloc[0]):\n",
        "            continue\n",
        "\n",
        "        current_descriptions = [parent_row['Description_PDF'].iloc[0]]\n",
        "        for child_hs in unique_hs_codes:\n",
        "            if child_hs.startswith(parent_hs) and len(child_hs) > len(parent_hs):\n",
        "                child_row = df_hsn[df_hsn['HS_Code_PDF'] == child_hs]\n",
        "                if not child_row.empty and pd.notna(child_row['Description_PDF'].iloc[0]):\n",
        "                    current_descriptions.append(child_row['Description_PDF'].iloc[0])\n",
        "        aggregated_descriptions[parent_hs] = \". \".join(list(dict.fromkeys(current_descriptions)))\n",
        "\n",
        "    df_hsn['Aggregated_Description_PDF'] = df_hsn['HS_Code_PDF'].map(aggregated_descriptions)\n",
        "    df_hsn['Aggregated_Description_PDF'].fillna(df_hsn['Description_PDF'], inplace=True)\n",
        "\n",
        "    print(\"HSN description aggregation complete.\")\n",
        "    return df_hsn"
      ],
      "metadata": {
        "id": "7rLGOD5mdaBF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}